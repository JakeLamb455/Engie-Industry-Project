{"cells":[{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710462009181,"execution_millis":10000,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"cell_id":"2864832923d148bda0e30183f1e5dd4b","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nimport os\nfrom datetime import timedelta\n\ndef combine_csv_files(directory):\n    \"\"\"\n    This function combines multiple CSV files from a given directory into a single pandas DataFrame. It also performs some data cleaning and transformation tasks.\n\n    Parameters:\n    directory (str): The path to the directory containing the CSV files.\n\n    Returns:\n    combined_df (pd.DataFrame): A DataFrame containing the combined data from all CSV files. The DataFrame includes the following columns:\n        - 'datetime': Timestamps converted to pandas datetime objects.\n        - 'dayofweek', 'objectname', 'datatype', 'avgvalue', 'hourending', 'marketday', 'year', 'month': Columns directly taken from the original CSV files.\n        - 'peaktype': This column is included if it exists in the original CSV files.\n        - 'datatype': This column's values are replaced based on a predefined mapping.\n\n    Note:\n    The function assumes that all CSV files have a similar structure and column names.\n    \"\"\"\n\n    dfs = []\n\n    for filename in os.listdir(directory):\n        \n        filepath = os.path.join(directory, filename)\n        df = pd.read_csv(filepath)\n        df['datetime'] = pd.to_datetime(df['datetime'])\n        dfs.append(df)\n\n    combined_df = pd.concat(dfs, ignore_index=True)\n    if 'peaktype' in combined_df.columns:\n        combined_df = combined_df[['datetime', 'dayofweek', 'objectname', 'datatype', 'avgvalue', 'hourending', 'marketday', 'peaktype', 'year', 'month']]\n        combined_df['datatype'] = combined_df['datatype'].replace({'RTLOAD': 'Load', 'GENERATION_SOLAR_RT': 'Solar', 'WINDDATA': 'Wind', 'TOTAL_RESOURCE_CAP_OUT': 'Outage'})\n    else:\n        combined_df = combined_df[['datetime', 'dayofweek', 'objectname', 'datatype', 'avgvalue', 'hourending', 'marketday', 'month', 'year']]\n        combined_df['datatype'] = combined_df['datatype'].replace({'LOAD_FORECAST': 'Load', 'SOLAR_STPPF': 'Solar', 'WIND_STWPF': 'Wind', 'TOTAL_RESOURCE_CAP_OUT': 'Outage'})\n    return combined_df\n\ndef datetime_split(df):\n    \"\"\"\n    Splits the 'datetime' column of a DataFrame into separate columns for year, month, day, hour, and week.\n\n    Parameters:\n    df (pandas.DataFrame): Input DataFrame with a 'datetime' column in string format.\n\n    Returns:\n    df (pandas.DataFrame): Output DataFrame with the 'datetime' column replaced by 'year', 'month', 'day', 'hour', and 'week' columns. The 'datetime' column is converted to datetime format, and the new columns are derived from it.\n\n    The 'year', 'month', and 'day' columns are self-explanatory. The 'hour' column contains the time information. The 'week' column contains the ISO week number.\n\n    Example:\n    >>> df = pd.DataFrame({'datetime': ['2022-01-01 13:45:30']})\n    >>> datetime_split(df)\n       year  month  day      hour  week\n    0  2022      1    1  13:45:30     1\n    \"\"\"\n   \n    df['datetime'] = pd.to_datetime(df['datetime'])\n\n    df['year'] = df['datetime'].dt.year\n    df['month'] = df['datetime'].dt.month\n    df['day'] = df['datetime'].dt.day\n    df['hour'] = df['datetime'].dt.time\n    df['week'] = df['datetime'].dt.isocalendar().week\n\n    return df\n\ndef Merge(Actual, Forecast):\n\n    \"\"\"\n    Merges two dataframes containing actual and forecast data on shared columns, computes residuals, and prepares a comprehensive dataframe.\n\n    This function merges the 'Actual' and 'Forecast' dataframes based on common columns: 'datetime', 'datatype', and 'objectname'. It performs an inner join to ensure that only rows present in both dataframes are included in the merged dataframe. The function then calculates the residuals (difference between actual and forecasted values), generates a 'Region_type' column by concatenating 'objectname' and 'datatype', and performs further data manipulation to structure the dataframe as required. It also splits the 'datetime' column into additional time-related columns and selects a specific set of columns for the final output.\n\n    Parameters:\n    - Actual (pandas.DataFrame): The dataframe containing actual data with columns including 'datetime', 'datatype', 'objectname', and others relevant to actual measurements.\n    - Forecast (pandas.DataFrame): The dataframe containing forecast data with columns matching those of the Actual dataframe necessary for merging and comparison.\n\n    Returns:\n    - pandas.DataFrame: A merged dataframe with columns for datetime, day of the week, object name, data type, actual measurements, hour ending, forecast measurements, peak type, residuals, region type, and split datetime components (year, month, day, hour).\n\n    Notes:\n    - The function assumes that 'datetime_split' is a predefined function that splits the 'datetime' column into 'year', 'month', 'day', and 'hour' columns.\n    - Columns 'year' and 'month' are dropped after the merge to streamline the dataframe before applying 'datetime_split'.\n    - The 'dayofweek', 'hour ending', and 'peaktype' columns are assumed to be part of the Actual dataframe and are carried over into the merged dataframe.\n    \"\"\"\n\n    Merged = Actual.merge(Forecast, how = 'inner', left_on = ['datetime', 'datatype', 'objectname'], right_on = ['datetime', 'datatype', 'objectname'])\n    Merged = Merged.rename(columns = {'datetime_x': 'datetime', 'dayofweek_x': 'dayofweek', 'avgvalue_x': 'Actual MW', 'year_x': 'year', 'month_x': 'month', 'hourending_x': 'hour ending', 'avgvalue_y': 'Forecast MW'})\n    Merged['residuals'] = Merged['Actual MW'] - Merged['Forecast MW']\n    Merged['Region_type'] = Merged[['objectname', 'datatype']].apply(lambda row: ' '.join(map(str, row)), axis=1)\n    Merged = Merged.drop(['year', 'month'], axis = 1)\n    Merged = datetime_split(Merged)\n    Merged = Merged[['datetime', 'dayofweek', 'objectname', 'datatype', 'Actual MW', 'hour ending', 'Forecast MW','peaktype', 'residuals', 'Region_type', 'year', 'month', 'day', 'hour']]\n    return Merged\n\n\ndef Combined_Files(Actual_directory, Forecast_directory):\n    \"\"\"\n    This function merges two dataframes, Actual and Forecast, based on certain common columns. It then performs a series of transformations and computations on the merged dataframe.\n\n    Parameters:\n    Actual (DataFrame): The actual data, expected to have columns ['datetime', 'datatype', 'objectname'].\n    Forecast (DataFrame): The forecasted data, expected to have columns ['day_ahead', 'datatype', 'objectname'].\n\n    Returns:\n    Merged (DataFrame): The merged dataframe with columns ['datetime', 'dayofweek', 'objectname', 'datatype', 'Actual MW', 'hour ending', 'Forecast MW','peaktype', 'residuals', 'Region_type', 'year', 'month', 'day', 'hour'].\n\n    The returned dataframe includes calculated residuals (the difference between actual and forecasted values), a combined region type, and split datetime into year, month, day, and hour.\n    \"\"\"\n    \n    Actuals = combine_csv_files(Actual_directory)\n    Forecasts = combine_csv_files(Forecast_directory)\n\n    Merged = Merge(Actuals, Forecasts)\n\n    return Merged\n\n\ndef percentile_dataframe(Actual_directory, Forecast_directory, Output_directory, Output_file_name):\n\n    \"\"\"\n    Generates a dataframe of percentile values for residuals, grouping by object name, data type, year, month, and day.\n\n    This function performs the following operations:\n    - Merges actual and forecast data from their respective directories into a single DataFrame.\n    - Groups the merged data by object name, data type, year, month, and day, and calculates the 10th, 25th, 50th, 75th, and 90th percentiles of residuals.\n    - Renames the columns for clarity and modifies the percentile column to include descriptive labels (e.g., \"10th\" for 0.1).\n    - Converts the month, year, and day columns to strings, and then combines them to form a new 'date' column in 'MM/DD/YYYY' format.\n    - Converts the new 'date' column to datetime format.\n    - Saves the resultant DataFrame as a CSV file in the specified output directory with the given output file name. If the output file name does not end with '.csv', the extension is appended automatically.\n\n    Parameters:\n    - Actual_directory (str): The directory path where the actual data files are located.\n    - Forecast_directory (str): The directory path where the forecast data files are located.\n    - Output_directory (str): The directory path where the output CSV file should be saved.\n    - Output_file_name (str): The name of the output file. If the name does not end with '.csv', the extension will be added automatically.\n\n    Returns:\n    - None: Outputs a message confirming the successful creation of the CSV file.\n    - Exports the df to csv\n\n    \"\"\"\n    \n    df = Combined_Files(Actual_directory, Forecast_directory)\n\n    perc_df_grouped = df.groupby(['objectname', 'datatype', 'year', 'month', 'day'])['residuals'].quantile([.1,.25,.5,.75,.9]).reset_index()\n        \n    perc_df_grouped = perc_df_grouped.rename(columns = {'level_5': 'percentile', 'residuals': 'perc_value'})\n        \n    perc_df_grouped['percentile'] = perc_df_grouped['percentile'].astype(str)\n        \n    perc_df_grouped['percentile'] = perc_df_grouped['percentile'].replace({'0.1':'10th', '0.25':'25th', '0.5':'50th', '0.75':'75th', '0.9':'90th'})\n        \n    perc_df_grouped['month'] = perc_df_grouped['month'].astype(str)\n        \n    perc_df_grouped['year'] = perc_df_grouped['year'].astype(str)\n        \n    perc_df_grouped['day'] = perc_df_grouped['day'].astype(str)\n    \n    perc_df_grouped['date'] = perc_df_grouped['month'] + '/' + perc_df_grouped['day'] + '/' + perc_df_grouped['year']\n        \n    perc_df_grouped['date'] = pd.to_datetime(perc_df_grouped['date'])\n\n    df = df[['objectname', 'datatype', 'year', 'month', 'day', 'dayofweek']]\n\n    df['year'] = df['year'].astype(str)\n\n    df['month'] = df['month'].astype(str)\n\n    df['day'] = df['day'].astype(str)\n\n    perc_df_grouped = perc_df_grouped.merge(df, how = 'left', on = ['objectname', 'datatype', 'year', 'month', 'day'])\n\n    perc_df_grouped = perc_df_grouped.drop_duplicates(subset=['objectname', 'datatype', 'year', 'month', 'day', 'percentile'])\n    \n    if '.csv' in Output_file_name:\n        path = Output_directory + Output_file_name\n    else:\n        path = Output_directory + Output_file_name + '.csv'\n\n    perc_df_grouped.to_csv(path)\n\n    return print(\"Succesfully created the csv!\")\n\n    \ndef residual_dataframe(Actual_directory, Forecast_directory, Output_directory, Output_file_name):\n\n    \"\"\"\n    Creates a residual dataframe by merging actual and forecast data, then saves it as a CSV file.\n\n    This function merges two data sets located in specified directories: one containing actual data and the other containing forecast data. The merged data set is then saved as a CSV file in the specified output directory with the given output file name. If the output file name does not end with '.csv', the extension is appended automatically.\n\n    Parameters:\n    - Actual_directory (str): The directory path where the actual data files are located.\n    - Forecast_directory (str): The directory path where the forecast data files are located.\n    - Output_directory (str): The directory path where the output CSV file should be saved.\n    - Output_file_name (str): The name of the output file. If the name does not end with '.csv', the extension will be added automatically.\n\n    Returns:\n    - None: Outputs a message confirming the successful creation of the CSV file.\n    - Exports the df to csv\n    \"\"\"\n\n    Merged = Combined_Files(Actual_directory, Forecast_directory)\n\n    if '.csv' in Output_file_name:\n        path = Output_directory + Output_file_name\n    else:\n        path = Output_directory + Output_file_name + '.csv'\n\n    Merged.to_csv(path)\n\n    return print(\"Succesfully created the csv!\")\n    \ndef price_dataframe(Actual_directory, Forecast_directory, Price_directory, Output_directory, Output_file_name):\n\n    \"\"\"\n    Merges actual, forecast, and price data from specified directories, then saves the merged dataframe as a CSV file.\n\n    This function performs the following operations:\n    - Reads price data from a directory and combines these files into a single DataFrame.\n    - Merges actual and forecast data from their respective directories into a single DataFrame.\n    - Replaces certain object names in the price data with predefined values.\n    - Merges the price DataFrame with the combined actual and forecast data DataFrame based on datetime and object name.\n    - Selects and renames specific columns in the merged DataFrame.\n    - Removes duplicate rows based on datetime, object name, and data type.\n    - Converts the price column to float type.\n    - Saves the final DataFrame as a CSV file in the specified output directory with the given output file name. If the output file name does not end with '.csv', the extension is appended automatically.\n\n    Parameters:\n    - Actual_directory (str): The directory path where the actual data files are located.\n    - Forecast_directory (str): The directory path where the forecast data files are located.\n    - Price_directory (str): The directory path where the price data files are located.\n    - Output_directory (str): The directory path where the output CSV file should be saved.\n    - Output_file_name (str): The name of the output file. If the name does not end with '.csv', the extension will be added automatically.\n\n    Returns:\n    - None: Outputs a message confirming the successful creation of the CSV file.\n    - Exports the df to csv\n    \n    \"\"\"\n\n    Price_df = combine_csv_files(Price_directory)\n\n    df = Combined_Files(Actual_directory, Forecast_directory)\n        \n    Price_df['objectname'] = Price_df['objectname'].replace({'LZ_WEST': 'WEST (ERCOT)', 'LZ_SOUTH': 'SOUTH', 'LZ_HOUSTON': 'HOUSTON', 'LZ_NORTH': 'NORTH'})\n        \n    df['datetime'] = pd.to_datetime(df['datetime'])\n        \n    Combined = df.merge(Price_df, how ='left', on = ['datetime', 'objectname'])\n\n    Combined = Combined[['datetime', 'dayofweek_x', 'objectname', 'datatype_x','Actual MW', 'hour ending', 'peaktype_x',  'Forecast MW', 'residuals', 'Region_type', 'year_x', 'month_x', 'day', 'hour', 'avgvalue']]\n\n    Combined = Combined.rename(columns={'dayofweek_x': 'day of week', 'datatype_x': 'datatype', 'peaktype_x': 'peaktype', 'year_x': 'year', 'month_x': 'month', 'avgvalue': 'price'})\n\n    Combined.drop_duplicates(subset=['datetime', 'objectname', 'datatype'], keep='first', inplace=True)\n\n    Combined['price'] = Combined['price'].astype(float)\n\n    if '.csv' in Output_file_name:\n        path = Output_directory + Output_file_name\n    else:\n        path = Output_directory + Output_file_name + '.csv'\n\n    Combined.to_csv(path)\n\n    return print(\"Succesfully created the csv!\")\n\n\ndef netload_dataframe(Actual_directory, Forecast_directory, Output_directory, Output_file_name):\n\n        \"\"\"\n        Generates a dataframe with net load calculations based on actual and forecast data, then saves it as a CSV file.\n\n        This function performs the following operations:\n        - Merges actual and forecast data from their respective directories into a single DataFrame.\n        - Converts the 'datetime' column to datetime format.\n        - Pivots the DataFrame to create a multi-level column structure with 'datatype' as the columns and 'Forecast MW', 'Actual MW', 'residuals' as the values.\n        - Flattens the multi-level columns and renames them by combining the original column names.\n        - Calculates the 'Actual Net Load' by subtracting the sum of actual solar and wind MW from the actual load MW.\n        - Calculates the 'Forecast Net Load' by subtracting the sum of forecast solar and wind MW from the forecast load MW.\n        - Renames the columns for clarity and removes duplicate rows based on 'datetime' and 'objectname'.\n        - Ensures that 'Actual Net Load', 'Actual MW Outage', and 'Forecast Net Load' are of float data type.\n        - Saves the final DataFrame as a CSV file in the specified output directory with the given output file name. If the output file name does not end with '.csv', the extension is appended automatically.\n\n        Parameters:\n        - Actual_directory (str): The directory path where the actual data files are located.\n        - Forecast_directory (str): The directory path where the forecast data files are located.\n        - Output_directory (str): The directory path where the output CSV file should be saved.\n        - Output_file_name (str): The name of the output file. If the name does not end with '.csv', the extension will be added automatically.\n\n        Returns:\n        - None: Outputs a message confirming the successful creation of the CSV file.\n        - Exports the created df to csv\n\n        \"\"\"\n\n        df = Combined_Files(Actual_directory, Forecast_directory)\n\n        df['datetime'] = pd.to_datetime(df['datetime'])\n\n        df = df.pivot_table(index=['datetime', 'objectname'], columns='datatype', values=['Forecast MW', 'Actual MW', 'residuals']).reset_index()\n\n        df.columns = ['{}_{}'.format(col[0], col[1]) for col in df.columns]\n\n        df['Actual Net Load'] = df['Actual MW_Load'] - (df['Actual MW_Solar'] + df['Actual MW_Wind'])\n\n        df['Forecast Net Load'] = df['Forecast MW_Load'] - (df['Forecast MW_Solar'] + df['Forecast MW_Wind'])\n\n        df = df.rename(columns = {'datetime_': 'datetime', 'objectname_': 'objectname'})\n\n        df.drop_duplicates(subset=['datetime', 'objectname'], keep='first', inplace=True)\n\n        df['Actual Net Load'] = df['Actual Net Load'].astype(float)\n\n        df['Actual MW_Outage'] = df['Actual MW_Outage'].astype(float)\n\n        df['Forecast Net Load'] = df['Forecast Net Load'].astype(float)\n\n        if '.csv' in Output_file_name:\n            path = Output_directory + Output_file_name\n        else:\n            path = Output_directory + Output_file_name + '.csv'\n\n        df.to_csv(path)\n\n        return print(\"Succesfully created the csv!\")\n\ndef SD_dataframe(Actual_directory, Forecast_directory, Output_directory, Output_file_name):\n\n        \"\"\"\n        Creates a CSV file containing the standard deviation (SD) of residuals for each day, grouped by object name, data type, year, month, and day.\n\n        This function calculates the daily standard deviation of residuals after merging actual and forecast data from their specified directories. The standard deviation is computed for each group defined by object name, data type, year, month, and day. The results are then saved to a CSV file in the specified output directory with the given output file name. If the output file name does not end with '.csv', the extension is appended automatically.\n\n        Parameters:\n        - Actual_directory (str): The directory path where the actual data files are located.\n        - Forecast_directory (str): The directory path where the forecast data files are located.\n        - Output_directory (str): The directory path where the output CSV file should be saved.\n        - Output_file_name (str): The name of the output file. If the name does not end with '.csv', the extension will be added automatically.\n\n        Returns:\n        - None: Outputs a message confirming the successful creation of the CSV file.\n        - Exports the created df to csv\n\n        \"\"\"\n    \n        df = Combined_Files(Actual_directory, Forecast_directory)\n\n        df_sd = df.groupby(['objectname', 'datatype', 'year', 'month', 'day'])['residuals'].std().reset_index()\n\n        df_sd.rename(columns = {'residuals': 'Daily_SD'}, inplace = True)\n\n        if '.csv' in Output_file_name:\n            path = Output_directory + Output_file_name\n        else:\n            path = Output_directory + Output_file_name + '.csv'\n\n        df.to_csv(path)\n        return print(\"Succesfully created the csv!\")\n\npercentile_dataframe('/work/ActualData/', '/work/ForecastData/', '/work/FINAL DATAFRAMES/', 'Percentile1')\n","block_group":"24d4896b83c247ca978f49a2c271bcfb","execution_count":null,"outputs":[{"name":"stdout","text":"Succesfully created the csv!\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/b9cfda9a-462c-4c64-a748-049d14cbf169"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1710457479949,"execution_millis":9315,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"cell_id":"176aa44fea9d47e9abee46457675f0ed","deepnote_cell_type":"code"},"source":"percentile_dataframe('/work/ActualData/', '/work/ForecastData/', '/work/FINAL DATAFRAMES/', 'Percentile1')\nSD_dataframe('/work/ActualData/', '/work/ForecastData/', '/work/FINAL DATAFRAMES/', 'Standard_deviation1')\nnetload_dataframe('/work/ActualData/', '/work/ForecastData/', '/work/FINAL DATAFRAMES/', 'Netload1')\nprice_dataframe('/work/ActualData/', '/work/ForecastData/', '/work/Prices_02_27_24/Prices RTLMP/', '/work/FINAL DATAFRAMES/', 'Price1')\nresidual_dataframe('/work/ActualData/', '/work/ForecastData/', '/work/FINAL DATAFRAMES/', 'Residual1')","block_group":"a1755d941bdc42e7b1a71a4ef47735cd","execution_count":null,"outputs":[{"name":"stdout","text":"Succesfully created the csv!\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/e3744d73-ca15-4045-b37d-8bceb5be56e6"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"fd19399066d34f25b0453e23bbac7bc3","deepnote_cell_type":"text-cell-p"},"source":"","block_group":"c8b641904e9f4feeaf572f7bfb45b4e7"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"ec081893547641ed82088d692a62a702","deepnote_cell_type":"text-cell-h1"},"source":"# ","block_group":"faa15f278c1a42629ccb8d57994c2187"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=65a70a80-d65f-4818-bf93-0169941c47a8' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_app_layout":"powerful-article","deepnote_app_reactivity_enabled":true,"deepnote_notebook_id":"278b70a0549b4900848479ae866c9184","deepnote_execution_queue":[]}}